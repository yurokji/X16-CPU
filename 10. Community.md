CHAPTER TEN

Community - The Network of Conscious Agents

“Silence is the language of god, all else is poor translation.”
—JALALUDDIN RUMI

“What can be said at all can be said clearly; and whereof one cannot speak thereof one must be silent.”
—LUDWIG WITTGENSTEIN , TRACTATUS LOGICO - PHILOSOPHICUS

T he delight of mystery, which we sometimes fetch from the netherworld of a black hole or a parallel universe, can be enjoyed, here and now, in your very chair. No mystery of science offers more intrigue, or greater perplexity, than the provenance of quotidian experiences—the taste of black coffee, the sound of a sneeze, the feel of your frame pressed into your chair. How does your brain serve up this magic? With what wave of a wand does three pounds of meat beget a conscious mind? That this remains a mystery is not, it would seem, due to a dearth of data: scientific journals are packed with scan upon sundry scan of a brain caught in the magician’s act. It’s rather that this cagey magician, despite unblinking scrutiny of its act, has never revealed any secrets. For Thomas Huxley in 1869, its legerdemain could be fathomed no better than the magic of Aladdin’s lamp. For us today, despite the breakthroughs of neuroscience, it remains just as surely unfathomable.

Why are we stumped? We can blame that basic tool of the conjurer’s trade: distraction. We have been lured, with potent miscues, to look over here —at the brain (or at the brain together with the body interacting with the environment). We have been misled to believe that the brain, or the embodied brain, somehow serves up the magic of consciousness. We have, in short, been duped.

For much of this book, I’ve sketched out how this has happened. Evolution shaped our perceptions to hide the truth and to guide adaptive behavior. It endowed us with an interface, consisting of objects in spacetime. It let us reason, with frequent success, about cause and effect within that interface. If I hit that cue ball just so, causing it to graze the eight ball over there, then I can pocket the eight ball and a chunk of cash. If I challenge that grizzly bear for the honey in that hive, the odds are that I will forfeit the honey and my life. Our grasp of cause and effect can dictate, in contexts both complex and crucial, our payoffs in fitness: a mate or a jilt, a meal or a miss, life or death. We do, and should, take it seriously. But it is a fiction—albeit a lifesaving fiction. Grasping virtual cause and effect in our interface grants us no more insight into the intrinsic operations of objective reality than grasping virtual cause and effect in a video game—fire this machine gun to obliterate that chopper; brandish this shield to deflect that blow; turn this wheel to steer this truck—grants a video virtuoso insight into the intrinsic operations of the transistors and machine code of her computer.

Physicists realize that spacetime is doomed, as well as its objects. 1 For principled reasons, Einstein’s spacetime cannot be foundational in physics. A new theory is required, in which spacetime, objects, their properties, and their fiction of cause and effect, sprout from a more primordial ground.

For most science and technology, this fictional cause and effect is handy—it helps us understand and exploit our interface. But if we try to understand our own conscious experiences, then this fiction gets in the way. Its lure, wired by evolution into even the best and brightest minds, poses the single greatest impediment to our progress. This fiction is built into each theory of consciousness that assumes, in accord with the Astonishing Hypothesis, that consciousness arises somehow from packs of neurons. This fiction is at the core of a proposal by Roger Penrose and Stuart Hameroff that conscious experience arises from an orchestrated collapse of certain quantum states in neural microtubules. 2 It is at the core of a proposal by Giulio Tononi and Christof Koch that each conscious experience is identical to some causal structure, neural or otherwise, that integrates information. 3 None of these proposals has offered a precise account for a single conscious experience. Precisely which orchestrated collapse creates, say, the taste of ginger?

Precisely which causal architecture for integrating information is the smell of pine? No answer has been offered and none ever will: these proposals set themselves an impossible task by assuming that objects in spacetime exist when not observed and have causal powers. This assumption works admirably within the interface. It utterly fails to transcend the interface: it cannot explain how conscious experiences might arise from physical systems such as embodied brains.

If no theory that starts with objects in spacetime can account for our conscious experiences, then where shall we begin? What new foundation might allow us to integrate the volumes of hard-earned data on mind, matter, and their correlations, into a rigorous theory? We can rephrase this question with a diagram we first encountered in chapter 7 (Figure 41 ). Suppose that I am an agent—a conscious agent—who perceives, decides, and acts. Suppose that my experiences of objects in spacetime are just an interface that guides my actions in an objective world—a world that does not consist of objects in spacetime. Then the question becomes: What is that world? What shall we place in that box labeled WORLD?

Fig. 41: The “perceive-decide-act” (PDA) loop. © DONALD HOFFMAN

Now this form of the question itself makes assumptions that may prove false. Perhaps, for instance, I’m just wrong to believe that I enjoy conscious experiences—that I experience the taste of mint tea and the smell of oatmeal cookies, and that I experience myself drinking that tea and eating those cookies. Perhaps there are no such experiences and I am deluded. The issue here is not whether I am infallible in my beliefs about my conscious experiences; the field of psychophysics provides clear evidence that no one is infallible. The issue is that I may be wrong to believe that I have any experience at all.

I cannot rule out this possibility. However, if I am wrong to believe that I have conscious experiences then, it would seem, I am wrong to believe anything. I should just eat, drink, and be merry, and grant that these pleasures themselves are but a delusion.

Let’s agree to put aside this possibility for the moment. Let’s grant, provisionally, that we have conscious experiences, that we are fallible and inconsistent in our beliefs about them, and that their nature and properties are legitimate subjects of scientific study.

Let’s also grant that our experiences, some of which we are consciously aware of and many of which we are not, inform our decisions and actions; again, taking these as ideas to be refined and revised by scientific study. Let us grant, in short, that we are conscious agents that perceive, decide, and act. The notion of a conscious agent is based on intuitions that are widely shared. It must, however, be made precise and then endure the rough and tumble of science. 4
Then the question remains: What is the objective world?

Perhaps our world is a computer simulation and we are just avatars that haunt it—as in movies such as The Matrix or The Thirteenth Floor , and games such as The Sims . Perhaps some geek, in another world, gets her kicks creating and controlling us and our world. That geek and her world might in turn be the digital plaything of a geek in a lower-level world. This might continue for multiple levels, until we reach some base level where the first simulation runs. Perhaps that level was conceived by a single edgy artist, or arose as a joint endeavor of a brilliant civilization beyond our imagination, or started as a scientific experiment to test whether new rules of physics could spark fascinating life forms whose creativity and pleasure was worth the pain they suffered.

This possibility is not dismissed by some serious thinkers, such as philosophers Nick Bostrom and David Chalmers, as well as tech entrepreneur Elon Musk, and it has interesting points in its favor. Spacetime, for instance, may be pixelated much like a computer screen; the three dimensions of space are a holographic inflation much like the virtual worlds of video games.

Could conscious experiences bubble out of a computer simulation? Some scientists and philosophers think so, but no scientific theory can explain how. Some suggest that each specific conscious experience—such as the taste of coffee I am savoring right now—is a specific computer program. But no such program has been found, and no one has any idea what principle could tie a program to an experience. For now, this proposal is a hand wave, not a scientific theory.

Others suggest that each kind of conscious experience—such as the kind of taste I have whenever I drink coffee—is a class of programs. But again, no such class of programs has been found, and no one has any idea what principle could tie a class of programs to a kind of experience. In short, we have no idea how simulations might conjure up conscious experiences. Simulations run afoul of the hard problem of consciousness: if we assume that the world is a simulation, then the genesis of conscious experiences remains a mystery.

It is, as we have seen, an empirical fact that specific conscious experiences are tightly correlated with specific patterns of activity in neural circuits. But no scientific theory that starts with neural circuitry has been able to explain the origin of consciousness. Steven Pinker suggests that we may have to live with this: “The last dollop in the theory—that it subjectively feels like something to be such circuitry—may have to be stipulated as a fact about reality where explanation stops.” 5

Pinker may be right: in our quest to understand the origin of subjective experience, if we start with circuitry then explanation stops. But could some other proposal fare better?

When facing a problem like this, scientists often heed the counsel of a fourteenth-century friar, William of Ockham: choose the simplest proposal that explains the data. This nugget, known as Occam’s Razor, is not a dictate of logic like modus tollens . 6 It may on occasion lead one astray. At a meeting of the Helmholtz Club, Francis Crick spotted such an occasion and remarked, “Many men have slit their throats with Occam’s Razor.”
Yet Occam’s Razor rightly enjoys stellar proponents. Einstein endorsed it in 1934: “It can scarcely be denied that the supreme goal of all theory is to make the irreducible basic elements as simple and as few as possible without having to surrender the adequate representation of a single datum of experience.” 7 The philosopher Bertrand Russell, in 1924, also gave it the nod: “Whenever possible, substitute constructions out of known entities for inferences to unknown entities.” 8

Occam’s Razor, applied to the science of consciousness, counsels a monism over an amphibious dualism, a theory based on entities of one kind rather than two. In accord with this advice, most attempts at a scientific theory of consciousness embrace physicalism. The basic constituents of objective reality are taken to be spacetime and its unconscious contents—particles, such as quarks and electrons, and fields, such as gravity and electromagnetism. Consciousness must somehow emerge from, or be caused by, or be identical to, these unconscious entities. Physicalists seek a theory that makes good on the Astonishing Hypothesis that conscious experiences can be generated by packs of neurons, which are themselves cooked up from unconscious ingredients.

As we have discussed, all attempts at a physicalist theory of consciousness have failed. They have produced no scientific theory and no plausible idea of how to build one. In each attempt so far, at just the moment when consciousness pops out of unconscious ingredients, a miracle occurs, and a metaphorical rabbit pops out of a hat. The failure, I think, is principled: you simply cannot cook up consciousness from unconscious ingredients.

Fig. 42: Two interacting agents. © DONALD HOFFMAN

Physicalism is not the only available monism. If we grant that there are conscious experiences, and that there are conscious agents that enjoy and act on experiences, then we can try to construct a scientific theory of consciousness that posits that conscious agents—not objects in spacetime—are fundamental, and that the world consists entirely of conscious agents. 9

Consider, for instance, a toy universe with just two conscious agents. Then the external “World” for each agent is the other agent. We end up with two conscious agents that interact. This is illustrated in Figure 42 , with one agent in bold type, and the other in light type. How one agent acts will influence how the other perceives; thus, a single arrow is labeled as both act and perceive .

We can consider universes that are more complex, with networks of three, four, or even an infinity of agents. The way one agent in a network perceives depends on the way that some other agents act. I call this monism conscious realism . Conscious realism and ITP are independent hypotheses; one may claim, for instance, that the reality behind our perceptual interface is not fundamentally conscious.

To turn conscious realism into a science, we need a mathematical theory of conscious experiences, conscious agents, their networks, and their dynamics. 10 We must show how conscious agents generate spacetime, objects, physical dynamics, and evolutionary dynamics. 11 We must get back quantum theory and general relativity, and generalizations of these theories that are mathematically precise.

“But,” you might say, “anyone who desiccates consciousness into mathematics has, we can safely assume, lost touch with the richness of their own consciousness and vanished into their own pointy head.”

Not so. A science of consciousness no more requires divorce from living consciousness than meteorology requires naiveté about thunderstorms, or epidemiology requires disregard for human affliction, or the science of evolutionary games requires virginity. To the contrary, it is fascination with the living subject that inspires a quest for rigor and deeper insight.

“But the proper ontology for science is physicalism. An ontology in which consciousness is fundamental is mere quackery. To reject physicalism, and embrace conscious realism, is to embrace pseudoscience.”

Many scientists do, in fact, endorse physicalism. Given that it has, time and again, proven of value in the progress of science and technology, one can hardly fault a scientist who looks askance at other ontologies, such as conscious realism.

Science, however, presumes no ontology. Ontologies are theories, and science—a method for evolving and testing theories—grants to no theory a special dispensation. Each theory, like each species, must compete to endure. A theory that today boasts a long reign may tomorrow, like so many erstwhile species, suffer a sudden extinction.

A certain physicalism that starts with spacetime and unconscious objects has enjoyed a long reign and, because Homo sapiens perceives fitness in the argot of objects in spacetime, a prima facie plausibility. But this physicalism appears unfit in some new territories of science, such as quantum gravity and the relation of biology to consciousness. The surprising insight of the FBT Theorem—that an organism that sees objective reality cannot dominate an organism of equal complexity that instead sees fitness—clashes with physicalism and warns of its demise.

“But what about conscious realism? Surely the plausibility of physicalism is surpassed only by the implausibility of conscious realism. Are we really to believe that an electron, which surely feels nothing, is itself conscious or, more outrageous still, a conscious agent ?”

This objection misinterprets conscious realism, which denies that physical objects exist when unperceived, and denies that they are conscious when perceived; physical objects are our conscious experiences, but they are not themselves conscious. The proper target of this objection is panpsychism, which claims that some physical objects also have consciousness. An electron, for instance, has unconscious properties such as position and spin, but may also have consciousness; a rock, however, might not be conscious, even if it consists of particles that are each conscious. Panpsychism appears unable to avoid dualism. 12 Brilliant thinkers have advocated panpsychism, which underscores the obstinacy of the hard problem of consciousness and the quandary of those trying to solve it. 13

Conscious realism is not panpsychism. The claim of conscious realism is better understood by looking in a mirror. There you see the familiar—your eyes, hair, skin, and teeth. What you don’t see is infinitely richer, and equally familiar—the world of your conscious experiences. It includes your dreams, fears, aspirations, love of music and sports, feelings of joy and grief, and the gentle pressure and warmth in your lips. The face you see in the mirror is a 3D icon, but you know firsthand that behind it is the vibrant world of your conscious experiences that transcends three dimensions. A person’s face is a small portal into their rich world of conscious experiences. The curve of lips and squint of eyes that form a smile no more capture the experience of real joy than the letters j- o-y . We can, despite this poverty of translation, see a friend smile and share their joy—because we are insiders, we know firsthand what transpires behind the scene when a face fashions a genuine smile. This same advantage of the insider lets us see a frown and feel disgust, see raised brows and feel surprise, and so on, with more than twenty kinds of emotions. 14

We can convey an experience by a mere expression. This is data compression of impressive proportions. How much information is wrapped up in an experience, say, of love? It’s hard to say. Our species has explored love through countless songs and poems and, apparently, failed to fathom its depths: each new generation feels compelled to explore further, to forge ahead with new lyrics and tunes. And yet, despite its unplumbed complexity, love is conveyed with a glance. This economy of expression is possible because my universe of experience, and my perceptual interface, overlaps yours.

There are, of course, differences. The visual experiences of the colorblind differ from the rich world of colors that most of us relish. The emotional experiences of a sociopath differ from ours in a way perhaps inconceivable to us, even in our darkest moments. But often the overlap is substantial, and grants us genuine, if but partial, access to the conscious world of another person, a world that would otherwise lie hidden—behind an icon of their body in our interface.

When we shift our gaze from humans to a bonobo or a chimpanzee, we find that the icon of each tells us far less about the conscious world that hides behind it. We share with these primates 99 percent of our DNA, but far less, it would seem, of our conscious worlds.
It took the brilliance and persistence of Jane Goodall to look beyond the icon of a chimp and glimpse inside its conscious world. 15
But as we shift our gaze again, from a chimp to a cat, then to a mouse, an ant, a bacterium, virus, rock, molecule, atom, and quark, each successive icon that appears in our interface tells us less and less about the efflorescence of consciousness behind the icon—again, “behind” in the same sense that a file lies “behind” its desktop icon. With an ant, our icon reveals so little that even Goodall could not, we suspect, probe its conscious world. With a bacterium, the poverty of our icon makes us suspect that there is, in fact, no such conscious world. With rocks, molecules, atoms, and quarks, our suspicion turns to near certainty. It is no wonder that we find physicalism, with its roots in an unconscious ground, so plausible.

We have been taken in. We have mistaken the limits of our interface for an insight into reality. We have finite capacities of perception and memory. But we are embedded in an infinite network of conscious agents whose complexity exceeds our finite capacities. So our interface must ignore all but a sliver of this complexity. For that sliver, it must deploy its capacities judiciously—more detail here, less there, next to nothing elsewhere. Hence our decline of insight as we shift our gaze from human to ant to quark. Our decline of insight should not be mistaken for an insight into decline—a progressive poverty inherent in objective reality. The decline is in our interface, in our perceptions. But we externalize it; we pin it on reality. Then we erect, from this erroneous reification, an ontology of physicalism.

Conscious realism pins the decline where it belongs—on our interface, not on an unconscious objective reality. Although each successive icon, in the sequence from human through ant to quark, offers a dimmer view of the conscious world that lies behind, this does not entail that consciousness itself is on a dimmer switch. The face I see in a mirror, being an icon, is not itself conscious.

But behind that icon flourishes, I know firsthand, a living world of conscious experiences. Likewise, the stone I see in a riverbed, being an icon, is not conscious nor inhabited by consciousness. It is a pointer to a living world of conscious experiences no less vibrant than my own—just far more obscured by the limitations of my icon. Such limitation is to be expected in the perceptions of any finite creature facing a reality that, in comparison to itself, is infinitely complex.

I have touted the virtue of precision in a theory of consciousness. It’s time to add some precision to the theory of conscious agents. Let’s leave the mathematical definition of a conscious agent to the appendix. But behind the mathematical definition are simple intuitions.
Figure 42 , from a few pages earlier, depicts two agents. Each agent has a set of possible experiences and a set of possible actions, and each agent perceives, decides, and acts. Each action is followed by an experience, perhaps desirable or perhaps not. Steal a carcass from lions: experience suffering. Pick a fig: experience a treat. Each action is a bet on future experiences. Sometimes you bet on a meal or a mate. Sometimes you bet your life.

To bet wisely, you must know the menu of options. At a horse race, for instance, your options might include picking Seabiscuit to show, place, or win; or hazarding a trifecta with Seabiscuit first, Secretariat second, and Big Red third.

A conscious agent needs a menu of actions, and a menu of the experiences that may follow. In mathematics, such a menu is called a measurable space . 16 It is the minimal structure you need to discuss probabilities, such as the probability that Seabiscuit will win.

So the menus of actions and experiences of a conscious agent are measurable spaces. That’s it. Nothing else. This is the minimal structure required to allow the theory of conscious agents to be testable by experiments. 17 If we could not describe probabilities of experiences and actions, we could not make empirical predictions from the theory. We could not do science.

A conscious agent is dynamic: it perceives, decides, and acts. When it perceives, its experience often changes; when it decides, its action often changes; when it acts, the experiences of other agents often change. Dynamics is conditional change. I see a blueberry muffin and butter croissant, and decide on the croissant; then I discover, behind the muffin, a chocolate eclair, and happily capitulate. My change in action, croissant to eclair, is a conditional change: it depends on my new experience, my tempting vision of a chocolate delight. Each new experience invites a new plan of action. In mathspeak, such a conditional change is a Markovian kernel . 18 The dynamics of a conscious agent—perceive, decide, and act—is, in each case, a Markovian kernel. Again, that’s it.

In sum, a conscious agent has experiences and actions, which are menus (measurable spaces). It perceives, decides, and acts, which are conditional changes (Markovian kernels). And it counts how many experiences it has had. That’s the entire definition of a conscious agent. It is, a mathematician would assure you, a simple bit of math.

“But,” you might object, “this math can also describe mechanical agents that are unconscious. So it says nothing about consciousness.”
This objection is a simple mistake. It’s like saying that numbers can count apples and so they can’t count oranges. Measurable spaces can describe unconscious events, such as flips of a coin. But they can also describe conscious events, such as experiences of taste and color. Probabilities and Markovian kernels can describe blind chance and unconscious decision, but also free will and conscious deliberation.

The definition of a conscious agent is just math. The math is not the territory. Just as a mathematical model of weather is not, and cannot create, blizzards and droughts, so also the mathematical model of conscious agents is not, and cannot create, consciousness. So, with this proviso, I offer a bold thesis, the Conscious Agent Thesis : every aspect of consciousness can be modeled by conscious agents. 19

The definition of conscious agent is precise, and this thesis is bold—not because I know it is right, but because I want to discover where, precisely, it may be wrong and, if possible, to repair the defect. This is standard procedure in science: present a clear theory, paint a big target, and hope that gifted colleagues will try, by logic and experiment, to shoot it down. Where a shot hits the mark, try to improve the theory.

A theory must suffer the slings and arrows of opponents, but it also needs proponents. Here are some virtues of conscious agents. They are computationally universal: networks of conscious agents can perform any cognitive or perceptual task, including learning, memory, problem solving, and object recognition. 20 Several such networks have been constructed, and offer an alternative to traditional neural networks. 21 Conscious agents offer a promising new framework for the construction of theories in cognitive neuroscience. This framework does not assume that biological neurons and their networks are the building blocks of cognition. Instead it takes consciousness as fundamental and then has the task of showing how spacetime, matter, and neurobiology can emerge as components of the perceptual interface of certain conscious agents.

Conscious agents can combine to form new conscious agents, and these new agents can again combine to form yet higher agents, ad infinitum. When two or more agents interact, each retains its individual agency, but together they also instantiate a new agent. The more each of the agents in an interaction can predict its experiences from its actions, the more integrated is their joint dynamics and the more cohesive is the new agent that they instantiate. The decisions and actions of a higher-level agent can, in turn, influence the dynamics of the agents in its instantiation.

The decisions of a conscious agent have a contribution by that agent at its own level, plus contributions from the decisions of the agents in its instantiation. The decisions of an agent at its own level may correspond to Daniel Kahneman’s “System 2” decisions, which are explicit and effortful, and the decisions further down in its instantiation may correspond to Kahneman’s “System 1” decisions, which appear more emotional, attitudinal, and automatic. 22

Combining agents into more complex agents can proceed ad infinitum, but unpacking agents into systems of simpler agents cannot. There is a bottom to the hierarchy of conscious agents. At the bottom reside the most elementary agents—“one-bit” agents—having just two experiences and two actions. The dynamics of a one-bit agent, and of interactions between two such agents, can be analyzed completely. 23 Here, at the foundation of agents, we can hope to connect with the foundations of spacetime, with physics at the Planck scale, and discern just how agents boot up a spacetime desktop.

The interface theory of perception contends that there is a screen—an interface—between us and objective reality. Can we hope to pierce that screen and see objective reality? Conscious realism says yes: we have met reality and it is like us. We are conscious agents, and so is objective reality. Beyond the interface lurks no Kantian noumenon, forever alien and impervious to our inquiry. Instead, we find agents like us: conscious agents. Their variety dwarfs the dazzling diversity of creatures that have paraded the earth and bequeathed to its sediments innumerable petrified mementos of their sojourn. We cannot imagine, concretely, even one new color. We cannot hope to imagine but a fraction of the varied experiences enjoyed by this multifarious host of agents. But despite our diversity, we share a unity: we are all agents, conscious agents.

“But,” you might object, “didn’t you earlier define ‘objective reality’ as that which exists even when no one observes? And don’t conscious experiences exist only when some agent observes? Haven’t you contradicted yourself when you propose conscious realism, and claim that objective reality consists of conscious agents?”

Indeed, for sake of argument, I adopted a notion of objective reality that is accepted by most physicalists. Then I used evolutionary assumptions that are also accepted by most physicalists to make the case against physicalism and its notion of objective reality. Now that I have presented that case, I am proposing a new ontology, and with it a new notion of objective reality in which conscious agents, with their experiences and structures, are central.

Conscious realism says that, despite our limits of imagination, a science of objective reality, of conscious agents and their interactions, is indeed possible. We can concretely imagine a space with at most three dimensions, but scientific theories routinely employ spaces with more dimensions, spaces that stump our imagination. In like manner, we can concretely imagine conscious experiences only within the tiny repertoire of Homo sapiens , but we can devise a scientific theory of all conscious agents, including those whose experiences stump our concrete imagination.

ITP and conscious realism reframe the classic problem of the relation between the brain and conscious experience. In chapter one, we discussed patients with split brains. When Joe Bogen severed a corpus callosum, his scalpel divided a unified brain into uncoupled hemispheres. This is a description of his surgery in the physicalist parlance of our interface. In reality, according to conscious realism, his scalpel split a conscious agent into two agents. The rich interactions of those two agents, which had instantiated a higher agent, became meager. We have seen that our interface can sometimes grant crude insight into the conscious realm behind—a smile can tell of joy, a deadpan tone of sorrow. Here, with its icon of a brain, our interface offers crude insight into agents and their combination—two lumps of meat joined by a corpus callosum tell of two agents interacting to form a new agent; two lumps with a severed callosum tell of an erstwhile unified agent now divorced into two distinct agents.

As we peer more closely at each hemisphere, our interface shows us networks of billions of neurons—again, perhaps granting crude insight into a realm of conscious agents that interact and instantiate higher agents. When we peer further into each neuron, and then into its chemistry, and finally into its physics, crude insight lapses into none.

A neuroscientist might object. “Cognitive neuroscience reveals that the vast majority of our mental processes are unconscious. We are unaware of the sophisticated processes by which we understand and produce speech, make decisions, learn, walk, understand, or transform images at the eye into visual worlds. Surely this vast swath of unconscious processing contradicts the claim of conscious realism that reality consists entirely of conscious agents. Conscious realism shipwrecks on the shoal of unconscious processes.”

But this again mistakes a limit of our interface for an insight into reality. When I talk with a friend, I assume that she is conscious. I cannot directly experience her consciousness. It is inaccessible to me, and I can at best infer what it might be like to be her. But I would be mistaken to conclude that, because I am not conscious of her consciousness, she must be unconscious. Similarly, I would be mistaken to conclude that, because I am not conscious of some of my own mental processes, those processes must be unconscious. I can be unaware of many of my own mental processes, and yet those processes could themselves be conscious to other agents in my instantiation.

A conscious agent enjoys a repertoire of experiences. It networks with many other agents, which enjoy a stupefying variety of disparate repertoires. So it cannot experience the vast majority of these exotic experiences. This holds in particular for the hierarchy of agents that constitute its own instantiation. An agent simply lacks the resources to experience all the experiences of all the agents in its instantiation, even though those agents contribute to its very self. An agent can at best wield its repertoire of experiences to paint, with broad brush, a crude depiction of its instantiation. In our case, we paint a body, brain, neurons, chemicals, and particles on a canvas of spacetime. Then we step back, admire our handiwork, and conclude that there’s nothing conscious to see here—a simple mistake that fosters physicalism and turns the problem of consciousness into a mystery.

A conscious agent is not just a repertoire of experiences. It decides and acts. But its actions are, by its very definition, distinct from its experiences: the diagram of an agent, for instance, has one box for “Experiences” and a separate box for “Actions.” This entails that a conscious agent can be aware, and yet not self-aware—not aware of its own decisions and actions. To be aware of itself, an agent must devote some of its experiences, some of its perceptual interface, to represent some of its own decisions and actions. Its interface must have an icon, or icons, that represent the decisions and actions of the agent itself. If it sees itself at all, it sees itself through its own interface—as through a glass, darkly. And, of necessity, incompletely.

No conscious agent can describe itself completely. The very attempt adds more experiences to the agent, which multiplies the complexity of its decisions and actions in light of those new experiences, which requires yet more experiences to capture those more complex decisions and actions, and so on in a vicious loop of incompleteness. A conscious agent must therefore remain, at least in part, unconscious to itself. Recall that what conscious realism claims to be fundamental is not just conscious experiences, but conscious agents . An agent cannot experience itself in its entirety, no matter how large its repertoire of experiences. From this limitation may arise philosophical conundrums, personal angst, and job security for psychotherapists.

There is, however, good reason to fabricate a self. If you experience your acts and their consequences, then you can learn. If this act leads to that noxious experience, then you can learn not to do this act. The richer your experience of your internal decisions and actions, the more latitude you have for nuanced interactions with the outside world. To know other agents, you must also know yourself. All knowledge is, in this sense, embodied.

Conscious realism must pay another promissory note. It must, from first principles, describe precisely the dynamics of conscious agents, and show how this dynamics, when projected into the interface of Homo sapiens, appears as modern physics and Darwinian evolution. This is a strong empirical constraint on a theory of agent dynamics: its projection into our spacetime interface must account for all the data that supports modern physics and evolution. In addition, it must make new predictions that can be tested by experiments.

What principles, and dynamics of agents, might fill the bill? I’m not yet sure. But a tantalizing thread stretches from conscious agents through natural selection to physics. A basic law of physics says, informally, that everything falls apart. As the poet William Drummond (1585–1649) put it, “all beneath the moon decays, And what by mortals in this world is brought, In Time’s great periods shall return to nought.” More precisely, this law—the second law of thermodynamics—says that the total entropy of any isolated system never decreases. The rot of entropy is an implacable enemy of life, a purveyor of decay and death. Life, as evolutionary psychologists John Tooby, Leda Cosmides, and Clark Barrett explain, has but one defense: “natural selection is the only known natural process that pushes populations of organisms thermodynamically uphill into higher degrees of functional order, or even offsets the inevitable increase in disorder that would otherwise take place.” 24

Entropy is the information you lack—the number of yes-no questions you would need, as when playing the parlor game of Twenty Questions, to fill in what you don’t know. But information, transacted in the currency of conscious experiences, is also the fungible commodity of conscious agents. Perhaps the dynamics of conscious agents is similar to the dynamics of cryptocurrencies, but with conscious experiences as the coin of the realm; enforcement of no double spending, when projected into the spacetime interface of Homo sapiens, might appear as a conservation law of physics. Or perhaps, as the physicist and inventor Federico Faggin has proposed, a central goal of conscious agents is mutual comprehension. 25 If so, then the dynamics of conscious agents may favor interactions that increase mutual information, and this dynamics, when projected from networks of agents into the interface of Homo sapiens , may appear there as evolution by natural selection. These are intriguing directions for research that may link insights from the theory of social networks—which describes why Google gets more hits than Hoffman—to the emergence of fitness functions in evolutionary biology.

Conscious realism advances an ontology radically different from the physicalism that dominates modern neuroscience, and science more generally. Radically different, but not radically new. Many key ideas of conscious realism and the interface theory of perception have appeared in prior sources, from ancient Greek philosophers such as Parmenides, Pythagoras, and Plato through more recent German philosophers such as Leibniz, Kant, and Hegel, and from eastern religions such as Buddhism and Hinduism to mystical strands of Islam, Judaism, and Christianity. The British philosopher and bishop George Berkeley clearly summarized some of the key ideas: “For as to what is said of the absolute existence of unthinking things without any relation to their being perceived, that seems perfectly unintelligible. Their ESSE is PERCIPI, nor is it possible they should have any existence out of the minds or thinking things which perceive them.” 26

If conscious agents and conscious realism contribute something new, it’s to assemble old ideas from philosophy and religion into a theory of consciousness that is precise and testable. This allows the ideas to be refined under the watchful eye of the scientific method.

Science, like philosophy and religious practice, is a human endeavor. It is not infallible. Each of the many attempts to demarcate, from first principles, science from pseudoscience remains, at best, controversial. 27 What science offers is not gold-standard beliefs, but a potent method for winnowing beliefs that derives its power from the way it engages with human nature. We are a species that argues. Experiments show, and evolutionary theory explains, that we reason best when we argue for an idea that we already believe, or against the idea of another that we disbelieve. 28 We did not evolve our ability to reason in order to pursue the truth.

We evolved it as a tool of social persuasion. As a result, our reasoning is plagued with foibles, such as a bias toward information that supports what we already believe. The scientific method exploits all of this. Each scientist argues for her idea, and against contradictory ideas of other scientists. In this argumentative context, our reason is at its sharpest: each idea garners the best support of reason and evidence its proponents can muster, and each endures the best impalement by reason and evidence its detractors can counter. Add to this sharpening of reason the demand that ideas be precise—mathematically precise, when possible—and the phoenix of science arises from foibles of human nature.

Science is not a theory of reality, but a method of inquiry. It orchestrates the better angels of our nature to promote reason, precision, productive dialog, and an appeal to evidence. It curbs our proclivity for the vague, deceptive, dogmatic, and imperious. Inquiry into any question that captures the human imagination—including meaning, purpose, values, beauty, and spirituality—deserves no less than the full benefit of this orchestration. Why deny ourselves our best chance to better understand?

Scholars of stature in science and religion have argued sometimes to the contrary. The US National Academy of Sciences, in its 1999 publication Science and Creationism , proposed that “Science tries to document the factual character of the natural world, and to develop theories that coordinate and explain these facts. Religion, on the other hand, operates in the equally important, but utterly different, realm of human purposes, meanings, and values—subjects that the factual domain of science might illuminate, but can never resolve.” The evolutionary biologist Stephen Jay Gould likewise claimed that “science and religion occupy two separate realms of human experience. Demanding that they be combined detracts from the glory of each.” 29

Richard Dawkins disagreed, arguing that “it is completely unrealistic to claim, as Gould and many others do, that religion keeps itself away from science’s turf, restricting itself to morals and values. A universe with a supernatural presence would be a fundamentally and qualitatively different kind of universe from one without. The difference is, inescapably, a scientific difference. Religions make existence claims, and this means scientific claims.” 30

I agree with Dawkins. If a system of thought, religious or otherwise, offers a claim that it wants taken seriously, then we should examine it with our best method of inquiry—the scientific method. That is taking it seriously.

Some topics—such as God, the good, reality, and consciousness—have been claimed to transcend the limited scope of human concepts and thus the methods of science. I have no quarrel with someone who claims this and then, being consistent, says no more about these topics. But if one does say more, then “What can be said at all can be said clearly” and probed with the scientific method. Can science describe who we are? I think so, in the sense that we can, by the scientific method, evolve and refine theories of who we are.

But if science cannot describe who we are, then imprecise natural languages such as English certainly cannot describe who we are. We have no better means of crafting explanations than the scientific method. An explanation that descended from on high, but could not be tested and debated, would be no explanation at all.

“But,” you might object, “the study of consciousness requires first-person experience. So it eludes science, which requires objective data obtained from a third-person point of view.”
This claim is mistaken. Science is not an ontology. It is not committed to a spacetime and objects that existed before any first-person experiences, and that must be studied from a third-person stance. Science is a method. It can test and discard ontologies. If our perceptions evolved by natural selection, then, according to the FBT Theorem, we should discard the ontology of physicalism. We should recognize that spacetime and objects are the perceptual interface used by Homo sapiens . They are our first-person experiences. The scientific study of physical objects in spacetime, even when conducted by large teams of scientists using advanced technologies, is necessarily a study of first-person experiences.

The moon I see is an icon of my interface, and the moon you see is an icon of your interface. There is no objective moon or spacetime that exists even when unperceived and that must therefore be examined from a third-person point of view. There are only first-person observations. But they do not elude science. They are the only data science ever had. Science compares first-person observations to see if they agree. If they do, then we gain confidence in our observations and the theories they support. But each physical object we study by experiment is just an icon in an interface, not an element of objective reality beyond that interface. Intersubjective agreement about a physical object or a meter reading does not entail that the object or reading exist when no one observes.

Conscious realism makes a bold claim: consciousness, not spacetime and its objects, is fundamental reality and is properly described as a network of conscious agents. 31 To earn its keep, conscious realism must do serious work ahead. It must ground a theory of quantum gravity, explain the emergence of our spacetime interface and its objects, explain the appearance of Darwinian evolution within that interface, and explain the evolutionary emergence of human psychology.

Conscious realism offers a fresh take on a sci-fi motif: Can artificial intelligence (AI) create real consciousness? Physicalists assume that fundamental particles are not conscious, but some conjecture that an object—a system of insentient particles—can generate consciousness if its internal dynamics instantiates the right complexity. Sophisticated AI can ignite real consciousness.

Conscious realism contends, to the contrary, that no physical object is conscious. If I see a rock, then that rock is part of my conscious experience, but the rock itself is not conscious. When I see my friend Chris, I experience an icon that I create, but that icon itself is not conscious. My Chris-icon opens a small portal into the rich world of conscious agents; a smiling icon, for instance, suggests a happy agent. When I see a rock, I also interact with conscious agents, but my rock-icon offers no insight, no portal, into their experiences.

So conscious realism reframes the AI question: Can we engineer our interface to open new portals into the realm of conscious agents? A hodgepodge of transistors affords no insight into that realm. But can transistors be assembled and programmed into an AI that opens a new portal into that realm? For what it’s worth, I think so. I think that AI can open new portals into consciousness, just as microscopes and telescopes open new vistas within our interface.

I also think that conscious realism can breach the wall between science and spirituality. This ideological barrier is a needless illusion, enforced by hoary misconceptions: that science requires a physicalist ontology that is anathema to spirituality, and that spirituality is impervious to the methods of science. I see ahead an uneasy truce and eventual rapprochement. Scientists won’t readily trade physicalism for conscious realism. Religious devotees will hesitate to demote ancient texts from citadels of authority to fallible founts of inspiration, and to embrace the iconoclastic debates and meticulous experiments of the scientific method. But in the end, both will recognize that they lost nothing of value, and in return secured a cleaner shot at our biggest questions: Who are we? Where are we? And what are we in the world for?

I mentioned that conscious agents combine to create more and more complex agents. This process eventuates in infinite agents, with infinite potential for experiences, decisions, and actions. The idea of an infinite conscious agent sounds much like the religious notion of God, with the crucial difference that an infinite conscious agent admits precise mathematical description. We can prove theorems about such agents and their relationship to finite agents such as us. In the process we can foster what might be called a scientific theology, in which mathematically precise theories of God can be evolved, sharpened, and tested with scientific experiments. I suspect, for instance, that an infinite conscious agent is not omniscient, omnipotent, omnipresent, or alone in its infinity. Scientific theology is not Promethean poaching in the sacrosanct property of ancient religions; it is applying our best cognitive and experimental tools to our dearest questions. The abstract discoveries of scientific theology would need to be translated into practical applications for laypersons. Religion can become an evolving science—informed by cognitive neuroscience and evolutionary psychology—whose salutary application to daily life also evolves.

The theory of God that emerges from a scientific theology need not posit a magician that flouts the laws of physics. These laws do not describe an unconscious reality; they describe the dynamics of conscious agents, finite and infinite, projected into the language and data structures of the spacetime interface of Homo sapiens . The laws of physics do not describe a machine, in which a marginalized ghost of consciousness must perform paranormal tricks to prove its existence. Consciousness need not flout scientific laws that are themselves projected descriptions of the dynamics of consciousness.

Suppose you drive with friends to a virtual-reality arcade to play volleyball. You slip on headsets and body suits, and find your avatars clad in swimsuits, immersed in sunshine, standing on a sandy beach with a volleyball net, surrounded by swaying palms and crying gulls. You serve the ball and start playing with abandon. After a while, one of your friends says he’s thirsty and will be right back. He slips out of his headset and body suit. His avatar collapses onto the sand, inert and unresponsive. But he’s fine. He just stepped out of the virtual-reality interface.

When we die, do we simply slip out of the spacetime interface of Homo sapiens ? I don’t know. But we have the theory of conscious realism, and the mathematics of conscious agents. Let’s do some science.

Conscious realism claims that consciousness is the fundamental nature of objective reality. I have been warned that this is an anachronism that misses the key message of the Copernican revolution: it’s not about us. We used to think that everything is about us and that therefore the earth must be the center of the universe. When Copernicus and Galileo discovered that it isn’t, this forced us to adjust our astronomy, but more importantly it forced us to transform our conception of ourselves. We are not center stage. We cling to a tiny rock in a nondescript corner of a vast universe. We aren’t even bit players. And this, I have been told, is what conscious realism gets wrong. By placing consciousness at the center of reality, conscious realism tries to return to a pre-Copernican era in which we could naïvely believe that we, and our consciousness, are the raison d’être of the universe.

This critique misreads conscious realism. It claims no central role for human consciousness. It posits countless kinds of conscious agents with a boundless variety of conscious experiences, most of which we cannot concretely imagine. There is nothing special or central about human beings as conscious agents. To say that consciousness is fundamental is not to say that human consciousness is fundamental or distinctive.

This critique also misreads the Copernican revolution. Yes, our perceptions misled us about our place in the universe. But its deeper message is this: our perceptions can mislead us about the very nature of the universe itself. We are prone to falsely believe that certain limitations and idiosyncrasies of our perceptions are genuine insights into objective reality. Galileo got the message and fingered some culprits. “I think that tastes, odors, colors, and so on . . . reside in consciousness. Hence if the living creature were removed, all these qualities would be wiped away and annihilated.” Galileo denied that our perceptions of tastes, odors, and colors are genuine insights into objective tastes, odors, and colors. There are, he claimed, no tastes, odors, or colors in objective reality. These are just features of our perceptions.

Galileo got the message, took a giant leap in the right direction, and then stopped. He still held that our perceptions of objects in space, with their shapes, positions, and momenta, are genuine insights into the true nature of objective reality. Most of us would agree.

But the theory of evolution by natural selection disagrees. It declares that the Copernican revolution extends farther than Galileo imagined. Objects, shapes, space, and time reside in consciousness. If the living creature were removed, all these qualities would be annihilated. Physics does not demur. Indeed, physicists concede that spacetime is doomed. It is not the primordial stage on which the drama of life plays out.

What is spacetime? This book has offered you the red pill. Spacetime is your virtual reality, a headset of your own making. The objects you see are your invention. You create them with a glance and destroy them with a blink.

You have worn this headset all your life. What happens if you take it off?
 
